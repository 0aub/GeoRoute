worker_processes auto;
error_log /var/log/nginx/error.log warn;
pid /var/run/nginx.pid;

events {
    worker_connections 1024;
    use epoll;
    multi_accept on;
}

http {
    include /etc/nginx/mime.types;
    default_type application/octet-stream;

    # Logging format
    log_format main '$remote_addr - $remote_user [$time_local] "$request" '
                    '$status $body_bytes_sent "$http_referer" '
                    '"$http_user_agent" "$http_x_forwarded_for" '
                    'rt=$request_time uct="$upstream_connect_time" '
                    'uht="$upstream_header_time" urt="$upstream_response_time"';

    access_log /var/log/nginx/access.log main;

    # Performance optimizations
    sendfile on;
    tcp_nopush on;
    tcp_nodelay on;
    keepalive_timeout 65;
    types_hash_max_size 2048;

    # Gzip compression
    gzip on;
    gzip_vary on;
    gzip_proxied any;
    gzip_comp_level 6;
    gzip_types text/plain text/css text/xml application/json application/javascript
               application/xml application/xml+rss text/javascript application/x-javascript
               image/svg+xml;

    # Security headers
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;
    add_header Referrer-Policy "strict-origin-when-cross-origin" always;

    # Rate limiting
    limit_req_zone $binary_remote_addr zone=api_limit:10m rate=10r/s;
    limit_req_zone $binary_remote_addr zone=general_limit:10m rate=30r/s;

    # Upstream definitions (supports multiple backend replicas)
    # Scale with: docker compose up -d --scale georoute-backend=3
    upstream backend {
        least_conn;  # Send to least busy server
        server georoute-backend:9001;
        keepalive 32;
    }

    upstream frontend {
        server georoute-ui:8080;
        keepalive 32;
    }

    # Main server block
    server {
        listen 80;
        listen [::]:80;
        server_name _;

        # Client body size for image uploads
        client_max_body_size 50M;

        # Frontend (React app) - No rate limiting for static files
        # Rate limiting on frontend breaks Vite dev server which loads many files
        location / {
            proxy_pass http://frontend;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;

            # WebSocket support for HMR in development
            proxy_read_timeout 86400;
        }

        # API endpoints
        location /api/ {
            limit_req zone=api_limit burst=20 nodelay;

            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_set_header Connection '';

            # Long timeout for AI operations (up to 3 minutes)
            proxy_read_timeout 180s;
            proxy_connect_timeout 60s;
            proxy_send_timeout 60s;

            # Disable buffering for SSE (Server-Sent Events)
            proxy_buffering off;
            proxy_cache off;

            # SSE specific headers
            proxy_set_header Cache-Control 'no-cache';
            chunked_transfer_encoding on;
        }

        # SSE progress endpoint (special handling)
        location /api/progress/ {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header Connection '';

            # SSE requires these settings
            proxy_buffering off;
            proxy_cache off;
            proxy_read_timeout 86400s;

            # Don't close connection
            proxy_set_header Cache-Control 'no-cache';
            chunked_transfer_encoding on;
        }

        # Health check endpoint (no rate limiting)
        location /api/health {
            proxy_pass http://backend;
            proxy_http_version 1.1;
            proxy_set_header Host $host;
            proxy_read_timeout 10s;
        }

        # Error pages
        error_page 500 502 503 504 /50x.html;
        location = /50x.html {
            root /usr/share/nginx/html;
            internal;
        }
    }
}
